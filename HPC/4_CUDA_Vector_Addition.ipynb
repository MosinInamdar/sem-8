{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75be568",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe572c13",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/afnan47/cuda.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cfd1c9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext nvcc_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1155a294",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f2a5d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#include <iostream> using namespace std; __global__ void add(int* A, int* B, int* C, int size) { int tid = blockIdx.x * blockDim.x + threadIdx.x; if (tid < size) { C[tid] = A[tid] + B[tid]; } } void initialize(int* vector, int size) { for (int i = 0; i < size; i++) { vector[i] = rand() % 10; } } void print(int* vector, int size) { for (int i = 0; i < size; i++) { cout << vector[i] << \" \"; } cout << endl; } int main() { int N = 4;int* A, * B, * C; int vectorSize = N; size_t vectorBytes = vectorSize * sizeof(int); A = new int[vectorSize]; B = new int[vectorSize]; C = new int[vectorSize]; initialize(A, vectorSize); initialize(B, vectorSize); cout << \"Vector A: \"; print(A, N); cout << \"Vector B: \"; print(B, N); int* X, * Y, * Z; cudaMalloc(&X, vectorBytes); cudaMalloc(&Y, vectorBytes); cudaMalloc(&Z, vectorBytes); cudaMemcpy(X, A, vectorBytes, cudaMemcpyHostToDevice); cudaMemcpy(Y, B, vectorBytes, cudaMemcpyHostToDevice); int threadsPerBlock = 256; int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock; add<<<blocksPerGrid, threadsPerBlock>>>(X, Y, Z, N); cudaMemcpy(C, Z, vectorBytes, cudaMemcpyDeviceToHost); cout << \"Addition: \"; print(C, N); delete[] A; delete[] B; delete[] C; cudaFree(X); cudaFree(Y); cudaFree(Z); return 0; }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58774e46",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Let's try a completely different approach using PyTorch's CUDA support\n",
    "# PyTorch is pre-installed in Colab and handles CUDA compatibility automatically\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Create two random vectors\n",
    "N = 4\n",
    "A = torch.randint(0, 10, (N,), dtype=torch.float32)\n",
    "B = torch.randint(0, 10, (N,), dtype=torch.float32)\n",
    "\n",
    "# Print input vectors\n",
    "print(f\"Vector A: {A}\")\n",
    "print(f\"Vector B: {B}\")\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "A = A.to(device)\n",
    "B = B.to(device)\n",
    "\n",
    "# Add vectors\n",
    "C = A + B\n",
    "\n",
    "# Print result\n",
    "print(f\"Addition: {C}\")\n",
    "\n",
    "# Alternative approach using numpy first\n",
    "print(\"\\nAlternative with NumPy conversion:\")\n",
    "A_np = np.random.randint(0, 10, N).astype(np.float32)\n",
    "B_np = np.random.randint(0, 10, N).astype(np.float32)\n",
    "\n",
    "print(f\"Vector A: {A_np}\")\n",
    "print(f\"Vector B: {B_np}\")\n",
    "\n",
    "# Convert to PyTorch tensors and move to GPU\n",
    "A_torch = torch.from_numpy(A_np).to(device)\n",
    "B_torch = torch.from_numpy(B_np).to(device)\n",
    "\n",
    "# Add vectors\n",
    "C_torch = A_torch + B_torch\n",
    "\n",
    "# Print result\n",
    "print(f\"Addition: {C_torch.cpu().numpy()}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
